@inproceedings{moulines2011non,
  title={Non-asymptotic analysis of stochastic approximation algorithms for machine learning},
  author={Moulines, Eric and Bach, Francis R},
  booktitle={Advances in Neural Information Processing Systems},
  pages={451--459},
  year={2011}
}

@inproceedings{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={315--323},
  year={2013}
}
@inproceedings{roux2012stochastic,
  title={A stochastic gradient method with an exponential convergence rate for finite training sets},
  author={Roux, Nicolas L and Schmidt, Mark and Bach, Francis R},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2663--2671},
  year={2012}
}
@article{boucheron2005theory,
  title={Theory of classification: A survey of some recent advances},
  author={Boucheron, St{\'e}phane and Bousquet, Olivier and Lugosi, G{\'a}bor},
  journal={ESAIM: probability and statistics},
  volume={9},
  pages={323--375},
  year={2005},
  publisher={Cambridge Univ Press}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@article{chandrasekaran2013computational,
  title={Computational and statistical tradeoffs via convex relaxation},
  author={Chandrasekaran, Venkat and Jordan, Michael I},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={13},
  pages={E1181--E1190},
  year={2013},
  publisher={National Acad Sciences}
}
@book{vapnik1998statistical,
  title={Statistical learning theory},
  author={Vapnik, Vlamimir},
  volume={1},
  year={1998},
  publisher={Wiley New York}
}

@article{dieuleveut2014,
  title={Non-parametric stochastic approximation with large step sizes},
  author={Dieuleveut, Aymeric and Bach, Francis},
  journal={arXiv preprint arXiv:1408.0361},
  year={2014}
}

@inproceedings{bach2013,
  title={Non-strongly-convex smooth stochastic approximation with convergence rate O (1/n)},
  author={Bach, Francis and Moulines, Eric},
  booktitle={Advances in Neural Information Processing Systems},
  pages={773--781},
  year={2013}
}

@book{kushner2003stochastic,
  title={Stochastic approximation and recursive algorithms and applications},
  author={Kushner, Harold J and Yin, George},
  volume={35},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The Annals of Mathematical Statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{schmidt2013minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Roux, Nicolas Le and Bach, Francis},
  journal={arXiv preprint arXiv:1309.2388},
  year={2013}
}

@article{DBLP:journals/corr/HeT15,
  author    = {Xi He and Martin Tak{\'{a}}c},
  title     = {Dual Free {SDCA} for Empirical Risk Minimization with Adaptive Probabilities},
  journal   = {CoRR},
  volume    = {abs/1510.06684},
  year      = {2015}
}

@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM Journal on Control and Optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM},
}

@incollection{hofmann2015variance,
title = {Variance Reduced Stochastic Gradient Descent with Neighbors},
author = {Hofmann, Thomas and Lucchi, Aurelien and Lacoste-Julien, Simon and McWilliams, Brian},
booktitle = {Advances in Neural Information Processing Systems 28},
pages = {2296--2304},
year = {2015},
publisher = {Curran Associates, Inc.},
}

 @inproceedings{frostig15,
  author    = {Roy Frostig and Rong Ge and Sham M. Kakade and Aaron Sidford},
  title     = {Competing with the Empirical Risk Minimizer in a Single Pass},
  booktitle = {The Conference on Learning Theory},
  pages     = {728--763},
  year      = {2015},
  }

@article{babanezhad2015stop,
  title={Stop Wasting My Gradients: Practical SVRG},
  author={Babanezhad, Reza and Ahmed, Mohamed Osama and Virani, Alim and Schmidt, Mark and Kone{\v{c}}n{\`y}, Jakub and Sallinen, Scott},
  journal={Advances in Neural Information Processing Systems},
  year={2015},
}
@InProceedings{jaggi12,
  title = 	 {Block-coordinate Frank-Wolfe optimization for structural SVMs},
  year = 	 {2012},
  booktitle = {The International Conference on Machine Learning}, 
  author={Lacoste-Julien, Simon and Jaggi, Martin and Schmidt, Mark and Pletscher, Patrick},
  volume = 28,
}

@inproceedings{shalev2008svm,
  title={SVM optimization: inverse dependence on training set size},
  author={Shalev-Shwartz, Shai and Srebro, Nathan},
  booktitle={The international conference on Machine learning},
  pages={928--935},
  year={2008},
}

@book{Matousek10,
  title={ Lecture notes on metric embeddings},
  author={ MatouÅ¡ek, Jir},
  year={2010},
}


@article{shalev2013stochastic,
  title={Stochastic dual coordinate ascent methods for regularized loss},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={The Journal of Machine Learning Research},
  volume={14},
  pages={567--599},
  year={2013},
}

@article{bousquet2002concentration,
  title={Concentration inequalities and empirical processes theory applied to the analysis of learning algorithms},
  journal={PhD thesis, Ecole Polytechnique},
  author={Bousquet, Olivier},
  year={2002}
}

@incollection{bousquet2004introduction,
  title={Introduction to statistical learning theory},
  author={Bousquet, Olivier and Boucheron, St{\'e}phane and Lugosi, G{\'a}bor},
  booktitle={Advanced Lectures on Machine Learning},
  pages={169--207},
  year={2004},
  publisher={Springer}
}

@inproceedings{agarwal2010fast,
  title={Fast global convergence rates of gradient methods for high-dimensional statistical recovery},
  author={Agarwal, Alekh and Negahban, Sahand and Wainwright, Martin J},
  booktitle={Advances in Neural Information Processing Systems},
  pages={37--45},
  year={2010}
}

@inproceedings{bousquet2008tradeoffs,
  title={The tradeoffs of large scale learning},
  author={Bousquet, Olivier and Bottou, L{\'e}on},
  booktitle={Advances in Neural Information Processing Systems},
  pages={161--168},
  year={2008}
}
@article{defazio2014finito,
  title={Finito: A faster, permutable incremental gradient method for big data problems},
  author={Defazio, Aaron J and Caetano, Tib{\'e}rio S and Domke, Justin},
  journal={arXiv preprint arXiv:1407.2710},
  year={2014}
 }
 
@book{nesterov2004introductory,
  title={Introductory lectures on convex optimization},
  author={Nesterov, Yurii},
  volume={87},
  year={2004},
  publisher={Springer Science \& Business Media}
}
@inproceedings{sridharan2009fast,
  title={Fast rates for regularized objectives},
  author={Sridharan, Karthik and Shalev-Shwartz, Shai and Srebro, Nathan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1545--1552},
  year={2009}
}
@article{shalev2011pegasos,
  title={Pegasos: Primal estimated sub-gradient solver for svm},
  author={Shalev-Shwartz, Shai and Singer, Yoram and Srebro, Nathan and Cotter, Andrew},
  journal={Mathematical programming},
  volume={127},
  number={1},
  pages={3--30},
  year={2011},
  publisher={Springer}
}

@inproceedings{defazio2014saga,
  title={SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1646--1654},
  year={2014}
}

@article{agarwal2015lower,
  title={A lower bound for the optimization of finite sums},
  author={Agarwal, Alekh and Bottou, L{\'e}on}},
  journal={The International Conference on Machine Learning},
  year={2015}
}
@Article{REF08a,
  author = 	 {Rong-En Fan and Kai-Wei Chang and Cho-Jui Hsieh and Xiang-Rui Wang and Chih-Jen Lin},
  title = {LIBLINEAR: A Library for Large Linear Classification},
  journal = {Journal of Machine Learning Research},
  year ={2008},
  volume =	 {9},
  pages =	 {1871--1874}
}
@Inbook{Nedic2001,
author="Nedi{\'{c}}, Angelia and Bertsekas, Dimitri",
chapter="Convergence Rate of Incremental Subgradient Algorithms",
title="Stochastic Optimization: Algorithms and Applications",
year="2001",
publisher="Springer US",
pages="223--264",
}
@book{boyd04,
 author = {Boyd, Stephen and Vandenberghe, Lieven},
 title = {Convex Optimization},
 year = {2004},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
} 
@article{pilanci2015newton,
  title={Newton Sketch: A Linear-time Optimization Algorithm with Linear-Quadratic Convergence},
  author={Pilanci, Mert and Wainwright, Martin J},
  journal={arXiv preprint arXiv:1505.02250},
  year={2015}
}


